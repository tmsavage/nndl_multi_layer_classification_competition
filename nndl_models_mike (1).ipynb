{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3",
      "metadata": {
        "id": "198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
      "metadata": {
        "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c"
      },
      "outputs": [],
      "source": [
        "# Create Dataset class for multilabel classification\n",
        "class MultiClassImageDataset(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.ann_df['image'][idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        super_idx = self.ann_df['superclass_index'][idx]\n",
        "        super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "        sub_idx = self.ann_df['subclass_index'][idx]\n",
        "        sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "# class MultiClassImageTestDataset(Dataset):\n",
        "#     def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "#         self.super_map_df = super_map_df\n",
        "#         self.sub_map_df = sub_map_df\n",
        "#         self.img_dir = img_dir\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __len__(self): # Count files in img_dir\n",
        "#         return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         img_name = str(idx) + '.jpg'\n",
        "#         img_path = os.path.join(self.img_dir, img_name)\n",
        "#         image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "\n",
        "#         super_idx = self.ann_df['superclass_index'][idx]\n",
        "#         super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "#         sub_idx = self.ann_df['subclass_index'][idx]\n",
        "#         sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "\n",
        "#         return image, super_idx, super_label, sub_idx, sub_label, img_name\n",
        "\n",
        "class MultiClassImageTestDataset(Dataset):\n",
        "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): # Count files in img_dir\n",
        "        return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = str(idx) + '.jpg'\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "YeG0lHc93QNC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeG0lHc93QNC",
        "outputId": "c387615a-6596-4d5d-ad3e-8b5f07358f79"
      },
      "outputs": [],
      "source": [
        "# # load the data from google drive and load into dataframes\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "file_path = 'Released_Data/'\n",
        "# sub_class = 'subclass_mapping.csv'\n",
        "# super_class = 'superclass_mapping.csv'\n",
        "# train_data = 'train_data.csv'\n",
        "\n",
        "# # Now you can read or manipulate the file\n",
        "# df_sub = pd.read_csv(file_path+'subclass_mapping.csv')\n",
        "# df_subclass = pd.read_csv(file_path+sub_class)\n",
        "# df_superclass = pd.read_csv(file_path+super_class)\n",
        "# df_train = pd.read_csv(file_path+train_data)\n",
        "\n",
        "# # Example: Print the content\n",
        "# df_subclass.head()\n",
        "\n",
        "train_ann_df = pd.read_csv(file_path + 'train_data.csv')\n",
        "super_map_df = pd.read_csv(file_path + 'superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv(file_path + 'subclass_mapping.csv')\n",
        "\n",
        "train_img_dir = file_path + 'train_shuffle'\n",
        "test_img_dir = file_path + 'test_shuffle'\n",
        "\n",
        "# count_subclass_87 = len(train_ann_df[train_ann_df['subclass_index'] == 87]) by default, there are 0 novel classes in training, so we should create our own\n",
        "\n",
        "# all classes with subclass 45, 57, and 29, 78 -> should get subclass label of 87 (novel)\n",
        "\n",
        "# target_classes = [45, 57, 29, 78]\n",
        "\n",
        "# Update the subclass_index to 87 for the specified classes\n",
        "# train_ann_df.loc[train_ann_df['subclass_index'].isin(target_classes), 'subclass_index'] = 87\n",
        "\n",
        "\n",
        "# image_preprocessing = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=(0), std=(1)),\n",
        "# ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "h165tAEj42bv",
      "metadata": {
        "id": "h165tAEj42bv"
      },
      "outputs": [],
      "source": [
        "# perform data manipulation: rotation, swapping, etc so that we can increase the size of the data set\n",
        "\n",
        "# Suggestion:\n",
        "# You should aim to train a generalizable model with all the techniques we have discussed\n",
        "# so far (e.g., data augmentation, weight decay, etc.) Other tricks may include potentially\n",
        "# building your local validation set for testing the model's generalization ability.\n",
        "\n",
        "# Data augmentation and normalization\n",
        "from torchvision import transforms\n",
        "\n",
        "# # Training data transformations\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random crop with scaling\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "# ])\n",
        "\n",
        "# # Testing data transformations\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.Resize(224),  # Resize to 224x224\n",
        "#     transforms.CenterCrop(224),  # Center crop to maintain the aspect ratio\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "# ])\n",
        "\n",
        "\n",
        "# Training data transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(64),  # Random crop with scaling\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Testing data transformations\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(64),  # Resize to 224x224\n",
        "    transforms.CenterCrop(64),  # Center crop to maintain the aspect ratio\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "# Apply data augmentation and normalization to datasets\n",
        "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=transform_train)\n",
        "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=transform_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "pM9I9OE-5B4m",
      "metadata": {
        "id": "pM9I9OE-5B4m"
      },
      "outputs": [],
      "source": [
        "# account for unlabeled data ()\n",
        "\n",
        "# https://cdn-uploads.piazza.com/paste/jcwopj0bkHVK/4e633d4b629ae6f0c6630bba588e0d783805da7fd03580939c93a350d54adde5/NNDL_Multi-label_Classification_Competition.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e7398553-8842-4ad8-b348-767921a22482",
      "metadata": {
        "id": "e7398553-8842-4ad8-b348-767921a22482"
      },
      "outputs": [],
      "source": [
        "# train_ann_df = pd.read_csv('train_data.csv')\n",
        "# super_map_df = pd.read_csv('superclass_mapping.csv')\n",
        "# sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
        "\n",
        "# train_img_dir = 'train_shuffle'\n",
        "# test_img_dir = 'test_shuffle'\n",
        "\n",
        "# image_preprocessing = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=(0), std=(1)),\n",
        "# ])\n",
        "\n",
        "# Create train and val split\n",
        "# train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
        "train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n",
        "\n",
        "# Create test dataset\n",
        "# test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=1,\n",
        "                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e0vRJiKa6254",
      "metadata": {
        "id": "e0vRJiKa6254"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Residual Block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.downsample = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.downsample(identity)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            ResidualBlock(32, 32),\n",
        "            ResidualBlock(32, 32),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            ResidualBlock(32, 64, stride=2),\n",
        "            ResidualBlock(64, 64),\n",
        "            ResidualBlock(64, 64),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            ResidualBlock(64, 128, stride=2),\n",
        "            ResidualBlock(128, 128),\n",
        "            ResidualBlock(128, 128),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Dynamically calculate the input size for the first fully connected layer\n",
        "        dummy_input = torch.randn(1, 3, 64, 64)\n",
        "        dummy_output = self._forward_conv(dummy_input)\n",
        "        self.fc1_input_size = dummy_output.view(dummy_output.size(0), -1).size(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.fc1_input_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3a = nn.Linear(128, 4)\n",
        "        self.fc3b = nn.Linear(128, 88)\n",
        "\n",
        "    def _forward_conv(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._forward_conv(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        super_out = self.fc3a(x)\n",
        "        sub_out = self.fc3b(x)\n",
        "\n",
        "        return super_out, sub_out\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "resnet_model = ResNet()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840",
      "metadata": {
        "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840"
      },
      "outputs": [],
      "source": [
        "# Simple CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "                        nn.Conv2d(32, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "                        nn.Conv2d(64, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.fc1 = nn.Linear(4*4*128, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3a = nn.Linear(128, 4)\n",
        "        self.fc3b = nn.Linear(128, 88)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        super_out = self.fc3a(x)\n",
        "        sub_out = self.fc3b(x)\n",
        "        return super_out, sub_out\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cpu'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            # print('1')\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "            # print('2')\n",
        "            self.optimizer.zero_grad()\n",
        "            # print('3')\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            # print('4')\n",
        "            # prob dist = [0.2, 0.05, ...]\n",
        "\n",
        "            # threasholding, \n",
        "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss/i:.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct = 0\n",
        "        sub_correct = 0\n",
        "        total = 0\n",
        "        running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "\n",
        "                total += super_labels.size(0)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation loss: {running_loss/i:.3f}')\n",
        "        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, return_predictions=False):\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
        "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "\n",
        "                test_predictions['image'].append(img_name[0])\n",
        "                test_predictions['superclass_index'].append(super_predicted.item())\n",
        "                test_predictions['subclass_index'].append(sub_predicted.item())\n",
        "\n",
        "        test_predictions = pd.DataFrame(data=test_predictions)\n",
        "\n",
        "        if save_to_csv:\n",
        "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1",
      "metadata": {
        "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1"
      },
      "outputs": [],
      "source": [
        "# Init model and trainer\n",
        "device = 'cpu'\n",
        "model = ResNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)\n",
        "\n",
        "new_trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7941c289-d9b1-4714-b788-898b3b889f58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7941c289-d9b1-4714-b788-898b3b889f58",
        "outputId": "0b83c0c6-4e14-4e5c-b2ce-99313060c283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Training loss: 2.175\n",
            "Validation loss: 2.641\n",
            "Validation superclass acc: 89.56 %\n",
            "Validation subclass acc: 44.30 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 2.160\n",
            "Validation loss: 2.817\n",
            "Validation superclass acc: 85.13 %\n",
            "Validation subclass acc: 40.98 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 2.061\n",
            "Validation loss: 2.652\n",
            "Validation superclass acc: 87.18 %\n",
            "Validation subclass acc: 45.57 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 2.083\n",
            "Validation loss: 2.743\n",
            "Validation superclass acc: 88.13 %\n",
            "Validation subclass acc: 44.94 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 2.064\n",
            "Validation loss: 2.646\n",
            "Validation superclass acc: 86.55 %\n",
            "Validation subclass acc: 43.99 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 2.028\n",
            "Validation loss: 2.625\n",
            "Validation superclass acc: 89.40 %\n",
            "Validation subclass acc: 45.57 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 1.975\n",
            "Validation loss: 2.566\n",
            "Validation superclass acc: 89.08 %\n",
            "Validation subclass acc: 46.20 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 1.940\n",
            "Validation loss: 2.456\n",
            "Validation superclass acc: 90.35 %\n",
            "Validation subclass acc: 47.31 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 1.847\n",
            "Validation loss: 2.672\n",
            "Validation superclass acc: 88.45 %\n",
            "Validation subclass acc: 43.35 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 1.854\n",
            "Validation loss: 2.592\n",
            "Validation superclass acc: 88.92 %\n",
            "Validation subclass acc: 46.84 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 1.808\n",
            "Validation loss: 2.672\n",
            "Validation superclass acc: 88.45 %\n",
            "Validation subclass acc: 45.73 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 1.798\n",
            "Validation loss: 2.553\n",
            "Validation superclass acc: 87.82 %\n",
            "Validation subclass acc: 47.94 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 1.822\n",
            "Validation loss: 2.599\n",
            "Validation superclass acc: 87.82 %\n",
            "Validation subclass acc: 47.78 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 1.741\n",
            "Validation loss: 2.608\n",
            "Validation superclass acc: 89.24 %\n",
            "Validation subclass acc: 48.10 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 1.731\n",
            "Validation loss: 2.496\n",
            "Validation superclass acc: 89.87 %\n",
            "Validation subclass acc: 49.21 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 1.733\n",
            "Validation loss: 2.464\n",
            "Validation superclass acc: 89.72 %\n",
            "Validation subclass acc: 47.47 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 1.734\n",
            "Validation loss: 2.496\n",
            "Validation superclass acc: 88.92 %\n",
            "Validation subclass acc: 48.89 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 1.698\n",
            "Validation loss: 2.667\n",
            "Validation superclass acc: 86.87 %\n",
            "Validation subclass acc: 45.73 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 1.703\n",
            "Validation loss: 2.526\n",
            "Validation superclass acc: 89.56 %\n",
            "Validation subclass acc: 50.47 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 1.626\n",
            "Validation loss: 2.428\n",
            "Validation superclass acc: 90.98 %\n",
            "Validation subclass acc: 47.47 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(20):\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    # torch.cuda.empty_cache()\n",
        "    trainer.train_epoch()\n",
        "    trainer.validate_epoch()\n",
        "    print('')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9a941d09",
      "metadata": {},
      "outputs": [],
      "source": [
        "stored_trainer = trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "16d17e37-1a08-4ae1-8517-a16ff4769622",
      "metadata": {
        "id": "16d17e37-1a08-4ae1-8517-a16ff4769622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test result\n",
            "data [tensor([[[[ 1.5639,  1.3584,  0.9303,  ..., -0.3027,  0.9132,  1.5125],\n",
            "          [ 1.5639,  1.3584,  0.9303,  ..., -0.3027,  0.9132,  1.5125],\n",
            "          [ 1.5468,  1.3413,  0.9132,  ..., -0.2856,  0.9303,  1.5297],\n",
            "          ...,\n",
            "          [ 0.3481,  0.4508,  0.6221,  ..., -0.8849, -0.7822, -0.7479],\n",
            "          [ 0.5364,  0.6049,  0.7762,  ..., -0.7650, -0.6623, -0.6281],\n",
            "          [ 0.6221,  0.6906,  0.8447,  ..., -0.6965, -0.6109, -0.5767]],\n",
            "\n",
            "         [[ 1.7283,  1.5007,  1.0630,  ..., -0.1800,  1.0630,  1.6933],\n",
            "          [ 1.7283,  1.5007,  1.0455,  ..., -0.1800,  1.0630,  1.6933],\n",
            "          [ 1.7108,  1.4832,  1.0280,  ..., -0.1625,  1.0805,  1.7108],\n",
            "          ...,\n",
            "          [ 0.4153,  0.5203,  0.6954,  ..., -1.0203, -0.9153, -0.8803],\n",
            "          [ 0.6078,  0.6779,  0.8529,  ..., -0.8978, -0.7927, -0.7577],\n",
            "          [ 0.6954,  0.7654,  0.9230,  ..., -0.8277, -0.7402, -0.7052]],\n",
            "\n",
            "         [[ 1.9777,  1.7511,  1.2980,  ..., -0.0267,  1.2108,  1.8208],\n",
            "          [ 1.9777,  1.7511,  1.2980,  ..., -0.0267,  1.2108,  1.8208],\n",
            "          [ 1.9603,  1.7337,  1.2805,  ..., -0.0092,  1.2282,  1.8383],\n",
            "          ...,\n",
            "          [ 0.6531,  0.7576,  0.9319,  ..., -1.2641, -1.1596, -1.1247],\n",
            "          [ 0.8448,  0.9145,  1.0888,  ..., -1.1421, -1.0376, -1.0027],\n",
            "          [ 0.9319,  1.0017,  1.1585,  ..., -1.0724, -0.9853, -0.9504]]]]), ('0.jpg',)]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_to_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mThis simple baseline scores the following test accuracy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mUnseen: 0.00 %\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[8], line 153\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, save_to_csv, return_predictions)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, data)\n\u001b[1;32m    152\u001b[0m inputs, img_name \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 153\u001b[0m inputs, super_labels, sub_labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), data[\u001b[38;5;241m1\u001b[39m], \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    155\u001b[0m super_outputs, sub_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\u001b[39;00m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "trainer.test(save_to_csv=False, return_predictions=True)\n",
        "\n",
        "'''\n",
        "This simple baseline scores the following test accuracy\n",
        "\n",
        "Superclass Accuracy\n",
        "Overall: 43.83 % # 30%\n",
        "Seen: 61.11 %\n",
        "Unseen: 0.00 %\n",
        "\n",
        "Subclass Accuracy\n",
        "Overall: 2.03 % # above 7 target\n",
        "Seen: 9.56 %\n",
        "Unseen: 0.00 %\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab70fb9-6e14-49f1-b9bb-5f3da6807399",
      "metadata": {
        "id": "6ab70fb9-6e14-49f1-b9bb-5f3da6807399"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
