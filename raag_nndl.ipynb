{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3",
   "metadata": {
    "id": "198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "xiEqdndwyIHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiEqdndwyIHN",
    "outputId": "0f12fb85-3c3b-4cec-f7bb-5ddc15cd2e76",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "# # Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
   "metadata": {
    "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Dataset class for multilabel classification\n",
    "class MultiClassImageDataset(Dataset):\n",
    "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
    "        self.ann_df = ann_df\n",
    "        self.super_map_df = super_map_df\n",
    "        self.sub_map_df = sub_map_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_df)\n",
    "    \n",
    "    def upscale_image(self, image):\n",
    "        # Upscale the image using bicubic interpolation\n",
    "        width, height = image.size\n",
    "        upscaled_image = image.resize((128,128), Image.BICUBIC)\n",
    "        return upscaled_image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.ann_df['image'][idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Upscale the image\n",
    "        image = self.upscale_image(image)\n",
    "\n",
    "        super_idx = self.ann_df['superclass_index'][idx]\n",
    "        super_label = self.super_map_df['class'][super_idx]\n",
    "\n",
    "        sub_idx = self.ann_df['subclass_index'][idx]\n",
    "        sub_label = self.sub_map_df['class'][sub_idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, super_idx, super_label, sub_idx, sub_label\n",
    "\n",
    "class MultiClassImageTestDataset(Dataset):\n",
    "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
    "        self.super_map_df = super_map_df\n",
    "        self.sub_map_df = sub_map_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): # Count files in img_dir\n",
    "        return len([fname for fname in os.listdir(self.img_dir)])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx) + '.jpg'\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c0a109b-2808-4a47-bc1b-98dfcccd42ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def random_split(dataset, lengths):\n",
    "#     r\"\"\"\n",
    "#     Randomly split a dataset into non-overlapping new datasets of given lengths.\n",
    "\n",
    "#     If a list of fractions that sum up to 1 is given,\n",
    "#     the lengths will be computed automatically as\n",
    "#     floor(frac * len(dataset)) for each fraction provided.\n",
    "\n",
    "#     After computing the lengths, if there are any remainders, 1 count will be\n",
    "#     distributed in round-robin fashion to the lengths\n",
    "#     until there are no remainders left.\n",
    "\n",
    "#     Optionally fix the generator for reproducible results, e.g.:\n",
    "\n",
    "#     >>> random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))\n",
    "#     >>> random_split(range(30), [0.3, 0.3, 0.4], generator=torch.Generator(\n",
    "#     ...   ).manual_seed(42))\n",
    "\n",
    "#     Args:\n",
    "#         dataset (Dataset): Dataset to be split\n",
    "#         lengths (sequence): lengths or fractions of splits to be produced\n",
    "#         generator (Generator): Generator used for the random permutation.\n",
    "#     \"\"\"\n",
    "#     if math.isclose(sum(lengths), 1) and sum(lengths) <= 1:\n",
    "#         subset_lengths: List[int] = []\n",
    "#         for i, frac in enumerate(lengths):\n",
    "#             if frac < 0 or frac > 1:\n",
    "#                 raise ValueError(f\"Fraction at index {i} is not between 0 and 1\")\n",
    "#             n_items_in_split = int(\n",
    "#                 math.floor(len(dataset) * frac)  # type: ignore[arg-type]\n",
    "#             )\n",
    "#             subset_lengths.append(n_items_in_split)\n",
    "#         remainder = len(dataset) - sum(subset_lengths)  # type: ignore[arg-type]\n",
    "#         # add 1 to all the lengths in round-robin fashion until the remainder is 0\n",
    "#         for i in range(remainder):\n",
    "#             idx_to_add_at = i % len(subset_lengths)\n",
    "#             subset_lengths[idx_to_add_at] += 1\n",
    "#         lengths = subset_lengths\n",
    "#         for i, length in enumerate(lengths):\n",
    "#             if length == 0:\n",
    "#                 warnings.warn(f\"Length of split at index {i} is 0. \"\n",
    "#                               f\"This might result in an empty dataset.\")\n",
    "\n",
    "#     # Cannot verify that dataset is Sized\n",
    "#     if sum(lengths) != len(dataset):    # type: ignore[arg-type]\n",
    "#         raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")\n",
    "\n",
    "#     indices = torch.randperm(sum(lengths)).tolist()\n",
    "#     offsets = [0] + list(itertools.accumulate(lengths))\n",
    "#     return [Subset(dataset, indices[offset : offset + length]) for offset, length in zip(offsets, lengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7398553-8842-4ad8-b348-767921a22482",
   "metadata": {
    "id": "e7398553-8842-4ad8-b348-767921a22482",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6858\n"
     ]
    }
   ],
   "source": [
    "train_ann_df = pd.read_csv('train_data_new.csv')\n",
    "super_map_df = pd.read_csv('superclass_mapping.csv')\n",
    "sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
    "\n",
    "train_img_dir = 'train_shuffle_transformed'\n",
    "test_img_dir = 'test_shuffle'\n",
    "\n",
    "image_preprocessing = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0), std=(1)),\n",
    "])\n",
    "\n",
    "# Create train and val split\n",
    "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
    "print(len(train_dataset))\n",
    "train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=1,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ANVuD0BXvWh0",
   "metadata": {
    "id": "ANVuD0BXvWh0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = []\n",
    "sup = []\n",
    "inp = []\n",
    "for i, data in enumerate(train_dataset):\n",
    "            inputs, super_labels, sub_labels = data[0], data[1], data[3]\n",
    "            sub.append(sub_labels)\n",
    "            sup.append(super_labels)\n",
    "            inp.append(inputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lsEbkzQSEuWG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "lsEbkzQSEuWG",
    "outputId": "8f4ecf2a-d460-4d0b-e329-973dc45d93c1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(sub, bins=30, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Frequency of Labels')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Labels')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840",
   "metadata": {
    "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840"
   },
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.MaxPool2d(2, 2)\n",
    "                      )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "                        nn.Conv2d(32, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.MaxPool2d(2, 2)\n",
    "                      )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "                        nn.Conv2d(64, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.MaxPool2d(2, 2)\n",
    "                      )\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*128, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3a = nn.Linear(128, 4)\n",
    "        self.fc3b = nn.Linear(128, 88)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        super_out = self.fc3a(x)\n",
    "        sub_out = self.fc3b(x)\n",
    "        return super_out, sub_out\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            super_outputs, sub_outputs = self.model(inputs)\n",
    "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Training loss: {running_loss/i:.3f}')\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        super_correct = 0\n",
    "        sub_correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                total += super_labels.size(0)\n",
    "                super_correct += (super_predicted == super_labels).sum().item()\n",
    "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        print(f'Validation loss: {running_loss/i:.3f}')\n",
    "        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n",
    "        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n",
    "\n",
    "    def test(self, save_to_csv=False, return_predictions=False):\n",
    "        if not self.test_loader:\n",
    "            raise NotImplementedError('test_loader not specified')\n",
    "\n",
    "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
    "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.test_loader):\n",
    "                inputs, img_name = data[0].to(device), data[1]\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                test_predictions['image'].append(img_name[0])\n",
    "                test_predictions['superclass_index'].append(super_predicted.item())\n",
    "                test_predictions['subclass_index'].append(sub_predicted.item())\n",
    "\n",
    "        test_predictions = pd.DataFrame(data=test_predictions)\n",
    "\n",
    "        if save_to_csv:\n",
    "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1",
   "metadata": {
    "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1"
   },
   "outputs": [],
   "source": [
    "# Init model and trainer\n",
    "device = 'cuda'\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7941c289-d9b1-4714-b788-898b3b889f58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7941c289-d9b1-4714-b788-898b3b889f58",
    "outputId": "8e45735f-164a-40d0-b350-87db25afb04f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training loss: 4.134\n",
      "Validation loss: 3.705\n",
      "Validation superclass acc: 84.34 %\n",
      "Validation subclass acc: 15.98 %\n",
      "\n",
      "Epoch 2\n",
      "Training loss: 3.179\n",
      "Validation loss: 3.214\n",
      "Validation superclass acc: 86.23 %\n",
      "Validation subclass acc: 25.95 %\n",
      "\n",
      "Epoch 3\n",
      "Training loss: 2.594\n",
      "Validation loss: 2.889\n",
      "Validation superclass acc: 88.45 %\n",
      "Validation subclass acc: 32.44 %\n",
      "\n",
      "Epoch 4\n",
      "Training loss: 2.242\n",
      "Validation loss: 2.904\n",
      "Validation superclass acc: 85.44 %\n",
      "Validation subclass acc: 34.81 %\n",
      "\n",
      "Epoch 5\n",
      "Training loss: 1.903\n",
      "Validation loss: 2.564\n",
      "Validation superclass acc: 90.66 %\n",
      "Validation subclass acc: 37.97 %\n",
      "\n",
      "Epoch 6\n",
      "Training loss: 1.592\n",
      "Validation loss: 2.390\n",
      "Validation superclass acc: 92.56 %\n",
      "Validation subclass acc: 42.72 %\n",
      "\n",
      "Epoch 7\n",
      "Training loss: 1.321\n",
      "Validation loss: 2.527\n",
      "Validation superclass acc: 92.56 %\n",
      "Validation subclass acc: 41.93 %\n",
      "\n",
      "Epoch 8\n",
      "Training loss: 1.067\n",
      "Validation loss: 2.512\n",
      "Validation superclass acc: 93.20 %\n",
      "Validation subclass acc: 45.41 %\n",
      "\n",
      "Epoch 9\n",
      "Training loss: 0.857\n",
      "Validation loss: 2.334\n",
      "Validation superclass acc: 93.04 %\n",
      "Validation subclass acc: 50.16 %\n",
      "\n",
      "Epoch 10\n",
      "Training loss: 0.670\n",
      "Validation loss: 2.475\n",
      "Validation superclass acc: 93.83 %\n",
      "Validation subclass acc: 48.10 %\n",
      "\n",
      "Epoch 11\n",
      "Training loss: 0.511\n",
      "Validation loss: 2.856\n",
      "Validation superclass acc: 91.14 %\n",
      "Validation subclass acc: 46.20 %\n",
      "\n",
      "Epoch 12\n",
      "Training loss: 0.417\n",
      "Validation loss: 3.010\n",
      "Validation superclass acc: 91.61 %\n",
      "Validation subclass acc: 48.58 %\n",
      "\n",
      "Epoch 13\n",
      "Training loss: 0.360\n",
      "Validation loss: 3.067\n",
      "Validation superclass acc: 92.25 %\n",
      "Validation subclass acc: 46.36 %\n",
      "\n",
      "Epoch 14\n",
      "Training loss: 0.263\n",
      "Validation loss: 3.428\n",
      "Validation superclass acc: 92.09 %\n",
      "Validation subclass acc: 45.89 %\n",
      "\n",
      "Epoch 15\n",
      "Training loss: 0.293\n",
      "Validation loss: 3.173\n",
      "Validation superclass acc: 92.72 %\n",
      "Validation subclass acc: 49.21 %\n",
      "\n",
      "Epoch 16\n",
      "Training loss: 0.199\n",
      "Validation loss: 3.338\n",
      "Validation superclass acc: 93.51 %\n",
      "Validation subclass acc: 51.58 %\n",
      "\n",
      "Epoch 17\n",
      "Training loss: 0.171\n",
      "Validation loss: 3.325\n",
      "Validation superclass acc: 91.77 %\n",
      "Validation subclass acc: 50.32 %\n",
      "\n",
      "Epoch 18\n",
      "Training loss: 0.193\n",
      "Validation loss: 3.465\n",
      "Validation superclass acc: 93.51 %\n",
      "Validation subclass acc: 50.16 %\n",
      "\n",
      "Epoch 19\n",
      "Training loss: 0.115\n",
      "Validation loss: 3.811\n",
      "Validation superclass acc: 92.88 %\n",
      "Validation subclass acc: 46.84 %\n",
      "\n",
      "Epoch 20\n",
      "Training loss: 0.155\n",
      "Validation loss: 3.702\n",
      "Validation superclass acc: 93.51 %\n",
      "Validation subclass acc: 49.53 %\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    trainer.train_epoch()\n",
    "    trainer.validate_epoch()\n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d17e37-1a08-4ae1-8517-a16ff4769622",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "16d17e37-1a08-4ae1-8517-a16ff4769622",
    "outputId": "8fe8bcdf-f61e-4267-aacb-3a2efc3419e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis simple baseline scores the following test accuracy\\n\\nSuperclass Accuracy\\nOverall: 43.83 %\\nSeen: 61.11 %\\nUnseen: 0.00 %\\n\\nSubclass Accuracy\\nOverall: 2.03 %\\nSeen: 9.56 %\\nUnseen: 0.00 %\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(save_to_csv=True, return_predictions=True)\n",
    "\n",
    "'''\n",
    "This simple baseline scores the following test accuracy\n",
    "\n",
    "Superclass Accuracy\n",
    "Overall: 43.83 %\n",
    "Seen: 61.11 %\n",
    "Unseen: 0.00 %\n",
    "\n",
    "Subclass Accuracy\n",
    "Overall: 2.03 %\n",
    "Seen: 9.56 %\n",
    "Unseen: 0.00 %\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ab70fb9-6e14-49f1-b9bb-5f3da6807399",
   "metadata": {
    "id": "6ab70fb9-6e14-49f1-b9bb-5f3da6807399",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 32, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 32, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 64, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.4),\n",
    "                        nn.Conv2d(64, 64, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 128, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 128, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "             nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.5),\n",
    "                        nn.Conv2d(128, 256, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.Conv2d(256, 256, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.Conv2d(256, 256, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.4),\n",
    "                        nn.Conv2d(256, 256, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.Conv2d(256, 256, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.Conv2d(256, 512, 3),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.4),\n",
    "         \n",
    "                      )\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3a = nn.Linear(128, 4)\n",
    "        self.fc3b = nn.Linear(128, 88)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block_1(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        super_out = self.fc3a(x)\n",
    "        sub_out = self.fc3b(x)\n",
    "        return super_out, sub_out\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            super_outputs, sub_outputs = self.model(inputs)\n",
    "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Training loss: {running_loss/i:.3f}')\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        super_correct = 0\n",
    "        sub_correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                total += super_labels.size(0)\n",
    "                super_correct += (super_predicted == super_labels).sum().item()\n",
    "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        print(f'Validation loss: {running_loss/i:.3f}')\n",
    "        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n",
    "        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n",
    "\n",
    "    def test(self, save_to_csv=False, return_predictions=False):\n",
    "        if not self.test_loader:\n",
    "            raise NotImplementedError('test_loader not specified')\n",
    "\n",
    "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
    "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.test_loader):\n",
    "                inputs, img_name = data[0].to(device), data[1]\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                test_predictions['image'].append(img_name[0])\n",
    "                test_predictions['superclass_index'].append(super_predicted.item())\n",
    "                test_predictions['subclass_index'].append(sub_predicted.item())\n",
    "\n",
    "        test_predictions = pd.DataFrame(data=test_predictions)\n",
    "\n",
    "        if save_to_csv:\n",
    "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afa16cf0-61ad-4e4f-b5b0-1eac5ddfc004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f17e686-814b-42a0-9bed-f8d49cc43f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inputs = []\n",
    "# super_labels = []\n",
    "# sub_labels = []\n",
    "# for i, data in enumerate(val_dataset):\n",
    "#                 inp, sup, sub = data[0], data[1], data[3]\n",
    "#                 inputs.append(str(i)+'.jpg')\n",
    "#                 super_labels.append(sup)\n",
    "#                 sub_labels.append(sub)\n",
    "# columns_1 = ['Index', 'Target']\n",
    "\n",
    "\n",
    "# # Create DataFrame\n",
    "# df_1 = pd.DataFrame(list(zip(inputs, super_labels)), columns=columns_1)\n",
    "\n",
    "# # Create DataFrame\n",
    "# df_2 = pd.DataFrame(list(zip(inputs, sub_labels)), columns=columns_1)\n",
    "\n",
    "# df_1.to_csv('val_super.csv', index=False)\n",
    "# df_2.to_csv('val_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "OKBHyQSK17-v",
   "metadata": {
    "id": "OKBHyQSK17-v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init model and trainer\n",
    "device = 'cuda'\n",
    "model = AutoEncoder().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dpKOIN0G1-8J",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpKOIN0G1-8J",
    "outputId": "cdfdf263-9ae1-4d70-c413-31061d175eab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training loss: 5.052\n",
      "Validation loss: 4.832\n",
      "Validation superclass acc: 65.99 %\n",
      "Validation subclass acc: 5.69 %\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mvalidate_epoch()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[68], line 90\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     88\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 90\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    trainer.train_epoch()\n",
    "    trainer.validate_epoch()\n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "n9lrDECjI0E_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "n9lrDECjI0E_",
    "outputId": "11fe65ee-76ff-4fa9-a270-e7fe9b5ea7bf",
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 8 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_to_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mThis simple baseline scores the following test accuracy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mUnseen: 0.00 %\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 122\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, save_to_csv, return_predictions)\u001b[0m\n\u001b[1;32m    119\u001b[0m         _, sub_predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(sub_outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    121\u001b[0m         test_predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(img_name[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 122\u001b[0m         test_predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuperclass_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43msuper_predicted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    123\u001b[0m         test_predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubclass_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(sub_predicted\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    125\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mtest_predictions)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 8 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "trainer.test(save_to_csv=True, return_predictions=True)\n",
    "\n",
    "'''\n",
    "This simple baseline scores the following test accuracy\n",
    "\n",
    "Superclass Accuracy\n",
    "Overall: 43.83 %\n",
    "Seen: 61.11 %\n",
    "Unseen: 0.00 %\n",
    "\n",
    "Subclass Accuracy\n",
    "Overall: 2.03 %\n",
    "Seen: 9.56 %\n",
    "Unseen: 0.00 %\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xO_-L8TjVcku",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xO_-L8TjVcku",
    "outputId": "b2f95d1c-8120-4ffb-daa2-5b45391d0db2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'example_test_predictions.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Select two columns\n",
    "selected_columns = df[['image', 'subclass_index']]\n",
    "\n",
    "# Rename one of the columns\n",
    "selected_columns = selected_columns.rename(columns={'image': 'ID'})\n",
    "selected_columns = selected_columns.rename(columns={'subclass_index': 'Target'})\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = 'sub_test.csv'  # Replace with the desired output file path\n",
    "selected_columns.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Select two columns\n",
    "selected_column = df[['image', 'superclass_index']]\n",
    "\n",
    "# Rename one of the columns\n",
    "selected_column = selected_column.rename(columns={'image': 'ID'})\n",
    "selected_column = selected_column.rename(columns={'superclass_index': 'Target'})\n",
    "print(selected_columns)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = 'super_test.csv'  # Replace with the desired output file path\n",
    "selected_column.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "960ce034-ac55-4081-b8dd-dfd56dc28a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685 12377\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [685, 12377]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_real), \u001b[38;5;28mlen\u001b[39m(df_predicted))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_real\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_predicted\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Display confusion matrix using seaborn heatmap\u001b[39;00m\n\u001b[1;32m     13\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(conf_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m             xticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted 1\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     15\u001b[0m             yticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual 1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [685, 12377]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_real = pd.read_csv('val_sub.csv')\n",
    "df_predicted = pd.read_csv('sub_test.csv')\n",
    "print(len(df_real), len(df_predicted))\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(df_real['Target'], df_predicted['Target'])\n",
    "\n",
    "# Display confusion matrix using seaborn heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "Bgt-1wcLvN7U",
   "metadata": {
    "id": "Bgt-1wcLvN7U",
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1345727966.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[61], line 24\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.decoder = nn.Sequential(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "self.encoder = nn.Sequential(\n",
    "                        nn.Conv2d(3, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.MaxPool2d(2, 2),\n",
    "                        nn.Conv2d(32, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.MaxPool2d(2, 2),\n",
    "                        nn.Conv2d(64, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                      )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Upsample(2),\n",
    "                        nn.Conv2d(64, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Upsample(2)\n",
    "                      )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*8, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3a = nn.Linear(128, 4)\n",
    "        self.fc3b = nn.Linear(128, 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ydcRgHlkmjiQ",
   "metadata": {
    "id": "ydcRgHlkmjiQ"
   },
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ### Convolutional section\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3, padding='same'),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, 3, padding='same'),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, 3, padding='same'),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 3, padding='same'),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, 3, padding='same'),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(4 * 4 * 8192, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 3 * 3 * 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(128, 3, 3)),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64, 32, 3,stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ConvTranspose2d(8, 3, 3, stride=2, output_padding=0)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(48387, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3a = nn.Linear(128, 4)\n",
    "        self.fc3b = nn.Linear(128, 88)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # print(x.shape)\n",
    "        x = self.decoder(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        super_out = self.fc3a(x)\n",
    "        sub_out = self.fc3b(x)\n",
    "        return super_out, sub_out\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, super_labels, sub_labels = data[0], data[1], data[3]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            super_outputs, sub_outputs = self.model(inputs)\n",
    "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Training loss: {running_loss/i:.3f}')\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        super_correct = 0\n",
    "        sub_correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                inputs, super_labels, sub_labels = data[0], data[1], data[3]\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                total += super_labels.size(0)\n",
    "                super_correct += (super_predicted == super_labels).sum().item()\n",
    "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        print(f'Validation loss: {running_loss/i:.3f}')\n",
    "        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n",
    "        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n",
    "\n",
    "    def test(self, save_to_csv=False, return_predictions=False):\n",
    "        if not self.test_loader:\n",
    "            raise NotImplementedError('test_loader not specified')\n",
    "\n",
    "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
    "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.test_loader):\n",
    "                inputs, img_name = data[0], data[1]\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                test_predictions['image'].append(img_name[0])\n",
    "                test_predictions['superclass_index'].append(super_predicted.item())\n",
    "                test_predictions['subclass_index'].append(sub_predicted.item())\n",
    "\n",
    "        test_predictions = pd.DataFrame(data=test_predictions)\n",
    "\n",
    "        if save_to_csv:\n",
    "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SdNNUKMNqTol",
   "metadata": {
    "id": "SdNNUKMNqTol"
   },
   "outputs": [],
   "source": [
    "# Init model and trainer\n",
    "device = 'cuda'\n",
    "model = AutoEncoder()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21RNJTjSqJ4T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "21RNJTjSqJ4T",
    "outputId": "29a3c9b5-d32f-41e6-929d-863d58e6e41c"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    trainer.train_epoch()\n",
    "    trainer.validate_epoch()\n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RPsawFCcqKFh",
   "metadata": {
    "id": "RPsawFCcqKFh"
   },
   "outputs": [],
   "source": [
    "trainer.test(save_to_csv=True, return_predictions=True)\n",
    "\n",
    "'''\n",
    "This simple baseline scores the following test accuracy\n",
    "\n",
    "Superclass Accuracy\n",
    "Overall: 43.83 %\n",
    "Seen: 61.11 %\n",
    "Unseen: 0.00 %\n",
    "\n",
    "Subclass Accuracy\n",
    "Overall: 2.03 %\n",
    "Seen: 9.56 %\n",
    "Unseen: 0.00 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed246b1-0ddc-4089-9651-5d2d18e4aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the zip file in your Google Drive\n",
    "zip_file_path = 'train_shuffle.zip'\n",
    "\n",
    "# Specify the destination folder for the extracted files\n",
    "extracted_folder_path = ''\n",
    "\n",
    "# Unzip the file\n",
    "!unzip \"$zip_file_path\" -d \"$extracted_folder_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c209837-4f4e-431f-9c3f-390283c4f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the zip file in your Google Drive\n",
    "zip_file_path = 'train_shuffle.zip'\n",
    "\n",
    "# Specify the destination folder for the extracted files\n",
    "extracted_folder_path = ''\n",
    "\n",
    "# Unzip the file\n",
    "!unzip \"$zip_file_path\" -d \"$extracted_folder_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d30da8-46f6-4397-8fc8-4a10597ca8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim_1, output_dim_2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "        self.classifier_1 = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim_1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.classifier_2 = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim_2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier_1(h)\n",
    "        y = self.classifier_2(h)\n",
    "        return x, y\n",
    "                      \n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            super_outputs, sub_outputs = self.model(inputs)\n",
    "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Training loss: {running_loss/i:.3f}')\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        super_correct = 0\n",
    "        sub_correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                total += super_labels.size(0)\n",
    "                super_correct += (super_predicted == super_labels).sum().item()\n",
    "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        print(f'Validation loss: {running_loss/i:.3f}')\n",
    "        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n",
    "        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n",
    "\n",
    "    def test(self, save_to_csv=False, return_predictions=False):\n",
    "        if not self.test_loader:\n",
    "            raise NotImplementedError('test_loader not specified')\n",
    "\n",
    "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
    "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.test_loader):\n",
    "                inputs, img_name = data[0].to(device), data[1]\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                test_predictions['image'].append(img_name[0])\n",
    "                test_predictions['superclass_index'].append(super_predicted.item())\n",
    "                test_predictions['subclass_index'].append(sub_predicted.item())\n",
    "\n",
    "        test_predictions = pd.DataFrame(data=test_predictions)\n",
    "\n",
    "        if save_to_csv:\n",
    "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2928fc-b5a1-4341-986a-251c886b1053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,\n",
    "                512, 'M']\n",
    "\n",
    "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,\n",
    "                'M', 512, 512, 512, 'M']\n",
    "\n",
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512,\n",
    "                512, 512, 'M', 512, 512, 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40512646-5966-48f2-a862-bd98063d2140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vgg_layers(config, batch_norm):\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "\n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = c\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e37954a3-ad43-4487-aecf-3cac71d87b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg11_layers = get_vgg_layers(vgg11_config, batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c125d3e-2dc8-4ed5-a22e-d36fd9cb1b69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): ReLU(inplace=True)\n",
      "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (24): ReLU(inplace=True)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg11_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b9c9427-018f-4640-b2d3-1d0272b0ec32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init model and trainer\n",
    "device = 'cuda'\n",
    "model = VGG(vgg11_layers, 4, 88).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "971a7443-1609-4caa-80e4-11ba7e241b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training loss: 734.730\n",
      "Validation loss: 7.621\n",
      "Validation superclass acc: 33.86 %\n",
      "Validation subclass acc: 1.90 %\n",
      "\n",
      "Epoch 2\n",
      "Training loss: 6.195\n",
      "Validation loss: 16.994\n",
      "Validation superclass acc: 40.82 %\n",
      "Validation subclass acc: 1.90 %\n",
      "\n",
      "Epoch 3\n",
      "Training loss: 12.121\n",
      "Validation loss: 6.823\n",
      "Validation superclass acc: 37.34 %\n",
      "Validation subclass acc: 1.27 %\n",
      "\n",
      "Epoch 4\n",
      "Training loss: 6.807\n",
      "Validation loss: 6.638\n",
      "Validation superclass acc: 37.03 %\n",
      "Validation subclass acc: 1.42 %\n",
      "\n",
      "Epoch 5\n",
      "Training loss: 39.257\n",
      "Validation loss: 32.227\n",
      "Validation superclass acc: 37.97 %\n",
      "Validation subclass acc: 0.79 %\n",
      "\n",
      "Epoch 6\n",
      "Training loss: 13.800\n",
      "Validation loss: 10.572\n",
      "Validation superclass acc: 42.41 %\n",
      "Validation subclass acc: 1.11 %\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mvalidate_epoch()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 62\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     60\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 62\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    trainer.train_epoch()\n",
    "    trainer.validate_epoch()\n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "086826dc-c7f9-490d-afac-296b621eb295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += self.downsample(identity)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(32, 32),\n",
    "            ResidualBlock(32, 32),\n",
    "            ResidualBlock(32, 32),\n",
    "            ResidualBlock(32, 32),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            ResidualBlock(32, 64, stride=2),\n",
    "            ResidualBlock(64, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, stride=2),\n",
    "            ResidualBlock(128, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Adjusted the input size for the first fully connected layer\n",
    "        self.fc1 = nn.Linear(128, 256)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3a = nn.Linear(128, 4)\n",
    "        self.fc3b = nn.Linear(128, 88)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        super_out = self.fc3a(x)\n",
    "        sub_out = self.fc3b(x)\n",
    "\n",
    "        return super_out, sub_out\n",
    "    \n",
    "class Trainer():\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            super_outputs, sub_outputs = self.model(inputs)\n",
    "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Training loss: {running_loss/i:.3f}')\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        super_correct = 0\n",
    "        sub_correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        device = self.device\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                total += super_labels.size(0)\n",
    "                super_correct += (super_predicted == super_labels).sum().item()\n",
    "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        print(f'Validation loss: {running_loss/i:.3f}')\n",
    "        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n",
    "        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n",
    "\n",
    "    def test(self, save_to_csv=False, return_predictions=False):\n",
    "        if not self.test_loader:\n",
    "            raise NotImplementedError('test_loader not specified')\n",
    "\n",
    "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
    "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.test_loader):\n",
    "                inputs, img_name = data[0].to(device), data[1]\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                test_predictions['image'].append(img_name[0])\n",
    "                test_predictions['superclass_index'].append(super_predicted.item())\n",
    "                test_predictions['subclass_index'].append(sub_predicted.item())\n",
    "\n",
    "        test_predictions = pd.DataFrame(data=test_predictions)\n",
    "\n",
    "        if save_to_csv:\n",
    "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            return test_predictions\n",
    "# Instantiate the model\n",
    "resnet_model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee3fb63c-1687-468b-be4a-7ff9443ba7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init model and trainer\n",
    "device = 'cuda'\n",
    "model = ResNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "trainer = Trainer(model, criterion, optimizer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f580594-f3fd-4e7a-b364-dad925bd06fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training loss: 5.245\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m70\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# trainer.validate_epoch()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 101\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    100\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m    102\u001b[0m     inputs, super_labels, sub_labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mMultiClassImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mann_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m][idx]\n\u001b[1;32m     15\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, img_name)\n\u001b[0;32m---> 16\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m super_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mann_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuperclass_index\u001b[39m\u001b[38;5;124m'\u001b[39m][idx]\n\u001b[1;32m     19\u001b[0m super_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuper_map_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m][super_idx]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:911\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    865\u001b[0m ):\n\u001b[1;32m    866\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageFile.py:275\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m                     b \u001b[38;5;241m=\u001b[39m b[n:]\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;66;03m# Need to cleanup here to prevent leaks\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m             \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtile \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadonly \u001b[38;5;241m=\u001b[39m readonly\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(70):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    trainer.train_epoch()\n",
    "    # trainer.validate_epoch()\n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4341c8d-a8df-4365-a946-fe749536290e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>superclass_index</th>\n",
       "      <th>subclass_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12372</th>\n",
       "      <td>12372.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12373</th>\n",
       "      <td>12373.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12374</th>\n",
       "      <td>12374.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12375</th>\n",
       "      <td>12375.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12376</th>\n",
       "      <td>12376.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12377 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image  superclass_index  subclass_index\n",
       "0          0.jpg                 1              10\n",
       "1          1.jpg                 0              51\n",
       "2          2.jpg                 2               1\n",
       "3          3.jpg                 2              13\n",
       "4          4.jpg                 1              24\n",
       "...          ...               ...             ...\n",
       "12372  12372.jpg                 0              80\n",
       "12373  12373.jpg                 2               3\n",
       "12374  12374.jpg                 2               3\n",
       "12375  12375.jpg                 0              56\n",
       "12376  12376.jpg                 1              85\n",
       "\n",
       "[12377 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(save_to_csv=True, return_predictions=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a2644d3-4dfc-4a5a-9038-5aa89d916289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "           image  superclass_index  subclass_index\n",
      "0          0.jpg                 1              10\n",
      "1          1.jpg                 0              51\n",
      "2          2.jpg                 2               1\n",
      "3          3.jpg                 2              13\n",
      "4          4.jpg                 1              24\n",
      "...          ...               ...             ...\n",
      "12372  12372.jpg                 0              80\n",
      "12373  12373.jpg                 2               3\n",
      "12374  12374.jpg                 2               3\n",
      "12375  12375.jpg                 0              56\n",
      "12376  12376.jpg                 1              85\n",
      "\n",
      "[12377 rows x 3 columns]\n",
      "              ID  Target\n",
      "0          0.jpg      10\n",
      "1          1.jpg      51\n",
      "2          2.jpg       1\n",
      "3          3.jpg      13\n",
      "4          4.jpg      24\n",
      "...          ...     ...\n",
      "12372  12372.jpg      80\n",
      "12373  12373.jpg       3\n",
      "12374  12374.jpg       3\n",
      "12375  12375.jpg      56\n",
      "12376  12376.jpg      85\n",
      "\n",
      "[12377 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'example_test_predictions.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Select two columns\n",
    "selected_columns = df[['image', 'subclass_index']]\n",
    "\n",
    "# Rename one of the columns\n",
    "selected_columns = selected_columns.rename(columns={'image': 'ID'})\n",
    "selected_columns = selected_columns.rename(columns={'subclass_index': 'Target'})\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = 'sub_test.csv'  # Replace with the desired output file path\n",
    "selected_columns.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Select two columns\n",
    "selected_column = df[['image', 'superclass_index']]\n",
    "\n",
    "# Rename one of the columns\n",
    "selected_column = selected_column.rename(columns={'image': 'ID'})\n",
    "selected_column = selected_column.rename(columns={'superclass_index': 'Target'})\n",
    "print(selected_columns)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = 'super_test.csv'  # Replace with the desired output file path\n",
    "selected_column.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10670c32-aeeb-447f-b891-f5727ad5447a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
